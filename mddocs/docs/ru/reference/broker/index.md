# Брокер сообщений { #message-broker }

Брокер сообщений - это компонент, используемый OpenLineage для хранения всех получаемых событий. Затем эти события обрабатываются [`message-consumer`][message-consumer] в пакетном режиме.

В настоящее время Data.Rentgen поддерживает только [Apache Kafka](https://kafka.apache.org/) в качестве брокера сообщений.

## Почему Kafka?

Другие популярные реализации серверов OpenLineage используют HTTP протокол для получения событий. По нашему опыту, Kafka гораздо лучше подходит для этого случая:

- Kafka разработана для масштабирования. Если производительности недостаточно, просто добавьте еще один брокер в кластер. Для HTTP серверов это не так просто, поскольку требует балансировки нагрузки на стороне обратного прокси или DNS.
- Kafka разработана для получения МНОЖЕСТВА событий в секунду, например миллионов, и максимально быстрого сохранения их на диск. Поэтому никакие события не теряются, даже если [`message-consumer`][message-consumer] перегружен - события уже сохранены на диск и будут обработаны позже.
- ETL скрипты в основном запускаются по расписанию. Обычный паттерн - почти никаких событий в течение дня, но огромные всплески каждый полный час (например, в 00:00, 01:00, 03:00, 12:00). Kafka используется как промежуточный буфер, который сглаживает эти всплески.
- События, хранящиеся в Kafka, могут читаться пакетами, даже если интеграция OpenLineage изначально отправляет их по одному. Пакетная обработка дает в 10 раз лучшую производительность по сравнению с обработкой отдельных событий.
- HTTP/HTTPS протокол имеет более высокую задержку, чем TCP протокол Kafka. Некоторые интеграции OpenLineage чувствительны к задержкам - например, [документация слушателя заданий Flink](https://nightlies.apache.org/flink/flink-docs-master/api/java/org/apache/flink/core/execution/JobListener.html) явно говорит: *Если вы заблокируете поток, вызывающий методы execute среды, возможно, будет заблокирован*. Чем меньше времени требуется для отправки ответа, тем лучше.

## Требования

- Apache Kafka 3.x. Рекомендуется использовать последнюю версию Kafka.

### Настройка

#### С Docker

- Установите [Docker](https://docs.docker.com/engine/install/)

- Установите [docker-compose](https://github.com/docker/compose/releases/)

- Выполните следующую команду:

  ```console
  $ docker compose --profile broker up -d --wait
  ...
  ```

  `docker-compose` загрузит образ Apache Kafka, создаст контейнер и том, а затем запустит контейнер.

  Точка входа образа создаст базу данных, если том пустой.
  Параметры можно задать через файл `.env` или секцию `environment` в `docker-compose.yml`

??? note "docker-compose.yml"

    ```yaml hl_lines="101-118 177" linenums="1"
    ----8<----
    docker-compose.yml
    ----8<----
    ```

??? note ".env.docker"

    ```ini hl_lines="7-20" linenums="1"
    ----8<----
    .env.docker
    ----8<----
    ```

#### Без Docker

Пожалуйста, следуйте [инструкции по установке Apache Kafka](https://kafka.apache.org/quickstart#quickstart_startserver).
