0.4.0 (2025-10-03)
==================

Features
--------

- Introduce new :ref:`http2kafka` component. (:issue:`281`)

  It allows using DataRentgen with OpenLineage HttpTransport.
  Authentication is done using personal tokens.

- Add REST API endpoints for managing personal tokens. (:issue:`276`)

  List of endpoints:
    * ``GET /personal-tokens`` - get personal tokens for current user.
    * ``POST /personal-tokens`` - create new personal token for current user.
    * ``PATCH /personal-tokens/:id`` - refresh personal token (revoke token and create new one).
    * ``DELETE /personal-tokens/:id`` - revoke personal token.


- Add new entities ``Tag`` and ``TagValue``. (:issue:`268`)

  Tags can be used as additional properties for another entities.
  This feature is still under construction.


- Added endpoint ``GET /v1/tags``. (:issue:`289`)

  Tag names and values can be paginated, searched by, or fetched by ids.

  .. dropdown:: Response example

    .. code-block:: json

        [
            {
            "id": 1,
            "name": "env",
            "values": [
                {
                  "id": 1,
                  "value": "dev"
                },
                {
                  "id": 2,
                  "value": "prod"
                }
              ]
            }
        ]


- Updated ``GET /v1/datasets`` to include ``tags: [...]`` in response. (:issue:`289`)

  .. dropdown:: Dataset response examples

    Before:

    .. code:: python

        {
            "id": "8400",
            "location": {...},
            "name": "dataset_name",
            "schema": {},
        }

    After:

    .. code:: python

        {
            "id": "25896",
            "location": {...},
            "name": "dataset_name",
            "schema": {...},
            "tags": [  # <---
                {
                    "id": "1",
                    "name": "environment",
                    "values": [
                        {
                            "id": "2",
                            "value": "production"
                        }
                    ]
                },
                {
                    "id": "2",
                    "name": "team",
                    "values": [
                        {
                            "id": "4",
                            "value": "my_awesome_team"
                        }
                    ]
                }
            ]
        }


- Added new filters to ``GET /v1/datasets`` endpoint. (:issue:`294`, :issue:`289`)

  Query params:
    - location_id: ``int``
    - tag_value_id: ``list[int]`` - if multiple values are passed, dataset should have all of them.


- Added new filters for ``GET /v1/jobs`` endpoint. (:issue:`319`)

  Query params:
    - location_id: ``int``
    - job_type: ``list[str]``


- Added new filters to ``GET /v1/runs`` endpoint. (:issue:`322`, :issue:`323`)

  Query params:
    - job_type: ``list[str]``
    - status: ``list[RunStatus]``
    - started_since: ``datetime | None``
    - started_until: ``datetime | None``
    - ended_since: ``datetime | None``
    - ended_until: ``datetime | None``
    - job_location_id: ``int | None``
    - started_by_user: ``list[str] | None``


- Added new endpoint ``GET /v1/jobs/types``. (:issue:`319`)


- Add custom ``dataRentgen_run`` and ``dataRentgen_operation`` facets. (:issue:`265`)

  These facets allow to:
    * Passing custom ``external_id``, ``persistent_log_url`` and other fields of Run.
    * Passing custom ``name``, ``description``, ``group``, ``positition`` fields of Operation.
    * mark event as containing only Operation or both Run + Operation data.

- Set ``output.type`` based on executed SQL query, e.g. ``INSERT``, ``UPDATE``, ``DELETE``, and so on. (:issue:`310`)


Improvements
------------

- Improve consumer performance by reducing DB load on reading operations. (:issue:`314`)


- Add workaround if OpenLineage emitted Spark application event with ``job.name=unknown``.  (:issue:`263`)

  This requires installing OpenLineage with this fix merged: https://github.com/OpenLineage/OpenLineage/pull/3848.


- Dataset symlinks with no inputs/outputs are no longer removed from lineage graph. (:issue:`269`)


- Make matching for addresses and locations more deterministic by converting them to lowercase. (:issue:`313`)

  Items ``oracle://host:1521`` and ``ORACLE://HOST:1521`` are the same item ``oracle://host:1521`` now.


- Make matching for datasets, jobs, tags and user names case-insensitive by using unique indexes on ``lower(name)`` expression. (:issue:`313`)

  Item ``database.schema.table`` and ``DATABASE.SCHEMA.TABLE`` are the same item now.

  As dataset canonical name depends on database naming convention (``UPPERCASE`` for Oracle, ``lowercase`` for Postgres),
  we can't convert them into one specific case (upper or lower). Instead we use first received value as canonical one.


Bug Fixes
---------

- For lineage with ``granularity=DATASET`` return real lineage graph. (:issue:`264`)

  v0.4.x resolved lineage by ``run_id``, but this may produce wrong lineage. v0.4.x now resolves lineage by ``operation_id``.


- Exclude self-referencing lineage edges in case ``granularity=DATASET``. (:issue:`261`)

  If some run uses the same table as both input and output (e.g. merging duplicates or performing some checks before writing),
  DataRentgen excludes ``dataset1 -> dataset1`` relations from lineage.

  This doesn't affect chains like ``dataset1 -> job1 -> dataset1`` or ``dataset1 -> dataset2 -> dataset1``.
